{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PopLE1ywNQsa"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e45O_NedNQsd"
   },
   "source": [
    "# Lab 2.1.1\n",
    "# *Data Wrangling and Munging with Pandas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qr08YR1PNQsf"
   },
   "source": [
    "## Part 1: Wrangling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH9yA6LINQsh"
   },
   "source": [
    "The term \"data wrangling\" is analogous to capturing wild horses and getting them into a fenced area; the horses are data and the fencing is your computer. The more common data wrangling tasks include:\n",
    "\n",
    "- reading flat files\n",
    "- reading Excel files\n",
    "- downloading from web pages\n",
    "  - csv\n",
    "  - html\n",
    "  - json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA : Exploration Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "baKB6_WIBp_8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8G9iecYNQsr"
   },
   "source": [
    "*It is good practice to display the library version numbers for future reference:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MC0XSmScBqAD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy:  1.24.3\n",
      "Pandas:  2.0.3\n"
     ]
    }
   ],
   "source": [
    "print('Numpy: ', np.__version__)\n",
    "print('Pandas: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzTKAG1LNQsx",
    "tags": []
   },
   "source": [
    "### CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE2wYKPNNQsy"
   },
   "source": [
    "Below are three attempts to load the file \"bikeshare.csv\" into a DataFrame named `bikes`. Why are they wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZV2HMWarNQsz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  instant,dteday,season,yr,mnth,hr,holiday,weekd...\n",
      "1  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...\n",
      "2  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "3  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "4  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...\n",
      "\n",
      "  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,0,3,13,16\n",
      "0  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...     \n",
      "1  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...     \n",
      "2  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...     \n",
      "3  5,2011-01-01,1,0,1,4,0,6,0,1,0.24,0.2879,0.75,...     \n",
      "4  6,2011-01-01,1,0,1,5,0,6,0,2,0.24,0.2576,0.75,...     \n",
      "\n",
      "  instant,dteday,season,yr,mnth,hr,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt\n",
      "0  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...                                                                   \n",
      "1  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...                                                                   \n",
      "2  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...                                                                   \n",
      "3  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...                                                                   \n",
      "4  5,2011-01-01,1,0,1,4,0,6,0,1,0.24,0.2879,0.75,...                                                                   \n"
     ]
    }
   ],
   "source": [
    "# wrong:\n",
    "bikes = pd.read_table('bikeshare.csv', header = None)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('bikeshare.csv', header = 1)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('bikeshare.csv', header = 0)\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSiMJN9NNQs4"
   },
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDFYVoPINQs6"
   },
   "source": [
    "Load the file \"bikeshare.csv\" into a DataFrame named `bikes`, and confirm that it was loaded properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZV2HMWarNQsz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  instant,dteday,season,yr,mnth,hr,holiday,weekd...\n",
      "1  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...\n",
      "2  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "3  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "4  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...\n",
      "\n",
      "  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,0,3,13,16\n",
      "0  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...     \n",
      "1  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...     \n",
      "2  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...     \n",
      "3  5,2011-01-01,1,0,1,4,0,6,0,1,0.24,0.2879,0.75,...     \n",
      "4  6,2011-01-01,1,0,1,5,0,6,0,2,0.24,0.2576,0.75,...     \n",
      "\n",
      "  instant,dteday,season,yr,mnth,hr,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt\n",
      "0  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...                                                                   \n",
      "1  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...                                                                   \n",
      "2  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...                                                                   \n",
      "3  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...                                                                   \n",
      "4  5,2011-01-01,1,0,1,4,0,6,0,1,0.24,0.2879,0.75,...                                                                   \n"
     ]
    }
   ],
   "source": [
    "#ANSWER:\n",
    "\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('../../DATA/bikeshare.csv', header = None)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('../../DATA/bikeshare.csv', header = 1)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('../../DATA/bikeshare.csv', header = 0)\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEwczD29NQtA"
   },
   "source": [
    "Note that we could have used `read.csv()` above. When is `read_table()` necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OsmNWLXNQtB"
   },
   "source": [
    "?:\n",
    "ANSWER: When `sep` is not the comma character, or we need fine control that `read.csv()` does not provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPEoeHGGNQtC"
   },
   "source": [
    "Flat files can be full of surprises. Here are some issues to watch out for:\n",
    "\n",
    "- separator character is something other than the comma\n",
    "  - \";\", \"|\", and tab are popular\n",
    "- newline character is something other than what the O/S expects\n",
    "  - Tip: Don't hard-code the character codes for carriage returns, linefeeds, etc. Use Python's built-in representation instead (e.g. Python translates \"\\n\" to the newline character and \"\\t\" to the tab character on any O/S).\n",
    "- truncated lines\n",
    "  - if there are empty fields at the end of a line it is possible that their separators will be missing, resulting in a \"jagged\" file\n",
    "- embedded commas or quotes\n",
    "  - a free-text field containing embedded commas may split into separate fields on input\n",
    "  - a free-text field containing embedded quotes may not parse correctly\n",
    "- unescaped characters\n",
    "  - the \"\\\" character indicates a control code to Python, which will break the I/O\n",
    "    - e.g. the substring \"\\u0123\" will be interpreted as Unicode(0123) -- which may not be what the file creator intended\n",
    "  - these may need to be fixed by loading whole strings and then parsing into a new data frame\n",
    "  \n",
    "Tip: Most issues can be dealt with by correctly specifying the parameters of the function you use to load the file. Read the doco before reading the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9LN5xo5zPLS0",
    "outputId": "b901c614-d42a-40c0-d482-6fd280d3bb6e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    }
   ],
   "source": [
    "#ANSWER:\n",
    "bikes = pd.read_table('../../DATA/bikeshare.csv', header = 0, sep = ',')\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0G5PtA2NQtC"
   },
   "source": [
    "### Reading Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TYELgCw6NQtD"
   },
   "outputs": [],
   "source": [
    "from pandas import ExcelFile  # Nb. Need to install xlrd from conda (it does not automatically install with pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XDjzKP6nNQtF"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dat/Iris.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdat/Iris.xls\u001b[39m\u001b[38;5;124m'\u001b[39m, sheet_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(io, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, engine\u001b[38;5;241m=\u001b[39mengine)\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1496\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1496\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1497\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1498\u001b[0m     )\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1503\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1371\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1369\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1372\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1374\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1375\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dat/Iris.xls'"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('dat/Iris.xls', sheet_name = 'Data')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjWx-Xo0NQtH"
   },
   "source": [
    "It is usually better to load data correctly than to meddle with the source file or load it 'warts and all' and then try to parse it in code. The Pandas functions for reading files have parameters that provide the control we need. For example, we could make multiple calls to `read_excel()`, using combinations of the `header`, `usecols`, `skiprows`, `nrows`, and `skipfooter` parameters to load one table at a time from a spreadsheet with multiple tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tC5kzTsMNQtI"
   },
   "source": [
    "Load the above file without the unwanted columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-P70uSXsNQtI"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTkOz1KsNQtK"
   },
   "source": [
    "### Importing Data Directly from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFHi_S4fNQtK"
   },
   "source": [
    "We usually want to store a local copy of a data file that we download from the Web, but when data retention is not a priority it is convenient to download the data directly into our running Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jS7P3oXQNQtL"
   },
   "source": [
    "#### Importing Text Files from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-hzkxRRNQtL"
   },
   "source": [
    "The web is the 'wild west' of data formats. However, we can usually expect good behaviour from files that are automatically generated by a service, such as the earthquake report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFuaZ82hNQtM"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_hour.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGgcXCzyNQtN"
   },
   "source": [
    "#### Importing HTML Files from the Web\n",
    "\n",
    "Working with unstructured HTML files relies heavily on library functions. This one, however, is well-structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4oVabZ6NQtO"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.ccra.com/airport-codes/'\n",
    "\n",
    "df = pd.read_html(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PiPCjFc7-281"
   },
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaWhHAk9NQtQ"
   },
   "source": [
    "#### Importing XML Files from the Web\n",
    "\n",
    "XML files are semi-structured, but you're at the mercy of the file creator. If every record has the same format it will be much easier, but practical applications often require a lot of custom code. Here are a few examples: https://pandas.pydata.org/docs/user_guide/io.html#io-read-xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppLnAmKVNQtQ"
   },
   "source": [
    "#### Importing JSON Files from the Web\n",
    "\n",
    "Like XML, JSON files are semi-structured and may require work to capture the schema into a dataframe. Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VB9EoRrNQtS"
   },
   "outputs": [],
   "source": [
    "url = 'https://microsoftedge.github.io/Demos/json-dummy-data/64KB.json'\n",
    "\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "df = pd.read_json(url, orient = 'columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIArBrFFNQtV"
   },
   "source": [
    "## Part 2: Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aFUJrhENQtW"
   },
   "source": [
    "Data munging is manipulating data to get it into a form that we can start running analyses on (which usually means getting the data into a DataFrame). Before we get to this stage, we may need to remove headers or footers, transpose columns to rows, split wide data tables into long ones, and so on. (Nb. Excel files can be particularly troublesome, because users can format their data in mixed, complex shapes.) Essentially, we need to follow Hadley Wickham's guidelines for tidy datasets (http://vita.had.co.nz/papers/tidy-data.html):\n",
    "\n",
    "The end goal of the cleaning data process:\n",
    "\n",
    "- each variable should be in one column\n",
    "- each observation should comprise one row\n",
    "- each type of observational unit should form one table\n",
    "- include key columns for linking multiple tables\n",
    "- the top row contains (sensible) variable names\n",
    "- in general, save data as one file per table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kmjox61xNQtW"
   },
   "source": [
    "### Dataset Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29PQdqUMNQtX"
   },
   "source": [
    "Once we have our dataset in a DataFrame (or Series, if our data is only 1-dimensional), we can start examining its size and content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04lspVeiNQtY"
   },
   "source": [
    "How many rows and columns are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DkO6SxSmNQtY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9LN5xo5zPLS0",
    "outputId": "b901c614-d42a-40c0-d482-6fd280d3bb6e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    }
   ],
   "source": [
    "#ANSWER:\n",
    "bikes = pd.read_table('../../DATA/bikeshare.csv', header = 0, sep = ',')\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "camJWA-DNQta"
   },
   "source": [
    "What are the column names in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "CUzgzxO1PLTX",
    "outputId": "2efde7d4-2ad3-4b91-930e-005240e4a283",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
       "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
       "       'casual', 'registered', 'cnt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iL7Cm_4NNQtc"
   },
   "source": [
    "What are the data types of these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "p7WciAwrNQtf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant         int64\n",
       "dteday         object\n",
       "season          int64\n",
       "yr              int64\n",
       "mnth            int64\n",
       "hr              int64\n",
       "holiday         int64\n",
       "weekday         int64\n",
       "workingday      int64\n",
       "weathersit      int64\n",
       "temp          float64\n",
       "atemp         float64\n",
       "hum           float64\n",
       "windspeed     float64\n",
       "casual          int64\n",
       "registered      int64\n",
       "cnt             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqHDi7_GNQtf"
   },
   "source": [
    "What is the (row) index for this DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=17379, step=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIJcLnsKNQth"
   },
   "source": [
    "https://www.dataquest.io/blog/python-json-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtxBEejpNQti"
   },
   "source": [
    "## Slicing and Dicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tzns_pFsNQtj"
   },
   "source": [
    "It is often preferable to refer to DataFrame columns by name, but there is more than one way to do this.\n",
    "Do `bikes['season']` and `bikes[['season']]` give the same object? Demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "9Xdl6Tv0PLTi",
    "outputId": "f01b4556-8036-4107-f3fe-b9c6c7fefaff",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.2879\n",
      "1    0.2727\n",
      "2    0.2727\n",
      "3    0.2879\n",
      "4    0.2879\n",
      "Name: atemp, dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n",
      "    atemp\n",
      "0  0.2879\n",
      "1  0.2727\n",
      "2  0.2727\n",
      "3  0.2879\n",
      "4  0.2879\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(bikes['atemp'].head())\n",
    "print(type(bikes['atemp']))\n",
    "print(bikes[['atemp']].head())\n",
    "print(type(bikes[['atemp']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsCATb2iNQtl"
   },
   "source": [
    "How would we use object notation to show the first 4 rows of `atemp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "T5D_UU5KNQtm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.2879\n",
       "1    0.2727\n",
       "2    0.2727\n",
       "3    0.2879\n",
       "Name: atemp, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.atemp[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWKI9FNDNQto"
   },
   "source": [
    "Algorithms that loop over multiple columns often access DataFrame columns by index. However, none of the following work (try them out by uncommenting / removing the \"#E: \" ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NgWFEEmWNQto"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([0], dtype='int32')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bikes[[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([0], dtype='int32')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "bikes[[0]]\n",
    "#E: bikes[0]\n",
    "#E: bikes[0,0]\n",
    "#E: bikes[[0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeUJ7D5qNQtq"
   },
   "source": [
    "What is the correct way to access the 1st row of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "d4Kidzz0NQtq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZa1v-2jNQts"
   },
   "source": [
    "What is the correct way to access the 2nd column of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "T4GmE0EsNQtt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2011-01-01\n",
       "1        2011-01-01\n",
       "2        2011-01-01\n",
       "3        2011-01-01\n",
       "4        2011-01-01\n",
       "            ...    \n",
       "17374    2012-12-31\n",
       "17375    2012-12-31\n",
       "17376    2012-12-31\n",
       "17377    2012-12-31\n",
       "17378    2012-12-31\n",
       "Name: dteday, Length: 17379, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSvqNbVUNQtu"
   },
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRPFEN1HNQtu"
   },
   "source": [
    "What is the Pandas `isnull` function for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xyw5qkWWNQtu"
   },
   "source": [
    "?\n",
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iby8s2VSNQtv"
   },
   "source": [
    "We can apply `isnull` to the `bikes` DataFrame to show the result for every element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "YRQY-1ViNQtv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  dteday  season     yr   mnth     hr  holiday  weekday  workingday  \\\n",
       "0    False   False   False  False  False  False    False    False       False   \n",
       "1    False   False   False  False  False  False    False    False       False   \n",
       "2    False   False   False  False  False  False    False    False       False   \n",
       "3    False   False   False  False  False  False    False    False       False   \n",
       "4    False   False   False  False  False  False    False    False       False   \n",
       "\n",
       "   weathersit   temp  atemp    hum  windspeed  casual  registered    cnt  \n",
       "0       False  False  False  False      False   False       False  False  \n",
       "1       False  False  False  False      False   False       False  False  \n",
       "2       False  False  False  False      False   False       False  False  \n",
       "3       False  False  False  False      False   False       False  False  \n",
       "4       False  False  False  False      False   False       False  False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IyZaICINQtw"
   },
   "source": [
    "However, we usually start at a higher level. How many nulls are in `bikes` altogether?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "L6a-0nVlPLTy",
    "outputId": "e9f5db5a-fd9e-4132-cac3-78210f838901",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['windspeed'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10jWUf4VNQty"
   },
   "source": [
    "If this result were nonzero we would next want to find out which columns contained nulls. How can this be done in one line of code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "qXq6AZ4WPLTz",
    "outputId": "d0b876b7-1796-4c86-ba23-12c59dac2d98",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0\n",
       "dteday        0\n",
       "season        0\n",
       "yr            0\n",
       "mnth          0\n",
       "hr            0\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          0\n",
       "atemp         0\n",
       "hum           0\n",
       "windspeed     0\n",
       "casual        0\n",
       "registered    0\n",
       "cnt           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1MsvXf7NQt0"
   },
   "source": [
    "What is the Numpy object `nan` used for? (Write a descriptive answer.)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "GaeGVh6ZNQt0"
   },
   "source": [
    "\n",
    "ANSWER:data is invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9bFlPsrNQt1"
   },
   "source": [
    "Write (and verify) a function that performs scalar division with built-in handling of the edge case (i.e. return a value instead of just trapping the error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "sAOyG-fsPLT1",
    "outputId": "26495e10-d177-48a2-d87b-b2f8efe1a569",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "def divide(dividend, divisor):\n",
    "    if divisor == 0:\n",
    "        quotient = np.nan\n",
    "    else:\n",
    "        quotient = dividend / divisor\n",
    "    return (quotient)\n",
    "\n",
    "print(divide(1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7Up8D6lNQt2"
   },
   "source": [
    "Apply the Pandas `isna` function to the following data objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "l_YvVav3NQt3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3 nan\n"
     ]
    }
   ],
   "source": [
    "x = 2.3\n",
    "y = np.nan\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "gBZ2c8fWPLT4",
    "outputId": "6887e847-e314-4a46-c4ec-39eb6df83d6f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(pd.isna(x), pd.isna(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "qJUM31pANQt5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. nan  3.]\n",
      " [ 4.  5. nan]]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "MYtR1zgdPLT6",
    "outputId": "72e4b826-755f-4976-d1fe-3e766df7c7a8",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True False]\n",
      " [False False  True]]\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(pd.isna(array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhFaZbzQNQt7"
   },
   "source": [
    "How is the pandas I/O parameter `na_values` used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mw-PvrTeNQt8"
   },
   "source": [
    "? ANSWER: Not available code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOW3ICgwNQt8"
   },
   "source": [
    "## Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZhJ9-XrNQt8"
   },
   "source": [
    "### Counts\n",
    "\n",
    "When there are categorical variables in a dataset we will want to know how many possible values there are in each column. (Nb. If the dataset is a sample of a larger one, our sample may not capture all possible values of every categorical.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RitKNRPCNQt8"
   },
   "source": [
    "How many (different) seasons are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "FNLe5AMoPLT8",
    "outputId": "b400b7ad-402c-4700-ae51-fe209abc11db",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "3    4496\n",
       "2    4409\n",
       "1    4242\n",
       "4    4232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['season'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peDZrNJjNQt-"
   },
   "source": [
    "### Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIKyD5LHNQt-"
   },
   "source": [
    "Print the range of the `instant`, `dteday`, and `windspeed` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "igQ895OFPLT-",
    "outputId": "abbba7c2-a09f-4b78-cc52-f7ce450d92f3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant: 1 to 17379\n",
      "dteday: 2011-01-01 to 2012-12-31\n",
      "windspeed: 0.0 to 0.8507\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print('instant:', bikes['instant'].min(), 'to', bikes['instant'].max())\n",
    "print('dteday:', bikes['dteday'].min(), 'to', bikes['dteday'].max())\n",
    "print('windspeed:', bikes['windspeed'].min(), 'to', bikes['windspeed'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "mVAOjyocNQt-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instant</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>8690.000000</td>\n",
       "      <td>5017.029500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4345.5000</td>\n",
       "      <td>8690.0000</td>\n",
       "      <td>13034.5000</td>\n",
       "      <td>17379.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>2.501640</td>\n",
       "      <td>1.106918</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>0.502561</td>\n",
       "      <td>0.500008</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnth</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>6.537775</td>\n",
       "      <td>3.438776</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>11.546752</td>\n",
       "      <td>6.914405</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>23.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>0.028770</td>\n",
       "      <td>0.167165</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>3.003683</td>\n",
       "      <td>2.005771</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>0.682721</td>\n",
       "      <td>0.465431</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weathersit</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>1.425283</td>\n",
       "      <td>0.639357</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>0.496987</td>\n",
       "      <td>0.192556</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atemp</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>0.475775</td>\n",
       "      <td>0.171850</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hum</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>0.627229</td>\n",
       "      <td>0.192930</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>0.190098</td>\n",
       "      <td>0.122340</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.2537</td>\n",
       "      <td>0.8507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casual</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>35.676218</td>\n",
       "      <td>49.305030</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>367.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>registered</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>153.786869</td>\n",
       "      <td>151.357286</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>115.0000</td>\n",
       "      <td>220.0000</td>\n",
       "      <td>886.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnt</th>\n",
       "      <td>17379.0</td>\n",
       "      <td>189.463088</td>\n",
       "      <td>181.387599</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>142.0000</td>\n",
       "      <td>281.0000</td>\n",
       "      <td>977.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean          std   min        25%        50%  \\\n",
       "instant     17379.0  8690.000000  5017.029500  1.00  4345.5000  8690.0000   \n",
       "season      17379.0     2.501640     1.106918  1.00     2.0000     3.0000   \n",
       "yr          17379.0     0.502561     0.500008  0.00     0.0000     1.0000   \n",
       "mnth        17379.0     6.537775     3.438776  1.00     4.0000     7.0000   \n",
       "hr          17379.0    11.546752     6.914405  0.00     6.0000    12.0000   \n",
       "holiday     17379.0     0.028770     0.167165  0.00     0.0000     0.0000   \n",
       "weekday     17379.0     3.003683     2.005771  0.00     1.0000     3.0000   \n",
       "workingday  17379.0     0.682721     0.465431  0.00     0.0000     1.0000   \n",
       "weathersit  17379.0     1.425283     0.639357  1.00     1.0000     1.0000   \n",
       "temp        17379.0     0.496987     0.192556  0.02     0.3400     0.5000   \n",
       "atemp       17379.0     0.475775     0.171850  0.00     0.3333     0.4848   \n",
       "hum         17379.0     0.627229     0.192930  0.00     0.4800     0.6300   \n",
       "windspeed   17379.0     0.190098     0.122340  0.00     0.1045     0.1940   \n",
       "casual      17379.0    35.676218    49.305030  0.00     4.0000    17.0000   \n",
       "registered  17379.0   153.786869   151.357286  0.00    34.0000   115.0000   \n",
       "cnt         17379.0   189.463088   181.387599  1.00    40.0000   142.0000   \n",
       "\n",
       "                   75%         max  \n",
       "instant     13034.5000  17379.0000  \n",
       "season          3.0000      4.0000  \n",
       "yr              1.0000      1.0000  \n",
       "mnth           10.0000     12.0000  \n",
       "hr             18.0000     23.0000  \n",
       "holiday         0.0000      1.0000  \n",
       "weekday         5.0000      6.0000  \n",
       "workingday      1.0000      1.0000  \n",
       "weathersit      2.0000      4.0000  \n",
       "temp            0.6600      1.0000  \n",
       "atemp           0.6212      1.0000  \n",
       "hum             0.7800      1.0000  \n",
       "windspeed       0.2537      0.8507  \n",
       "casual         48.0000    367.0000  \n",
       "registered    220.0000    886.0000  \n",
       "cnt           281.0000    977.0000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5oDTJHoNQt_"
   },
   "source": [
    "Compute and print the overall minimum and maximum of the numeric data columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "jMYzYv73PLUA",
    "outputId": "4eab5295-b61e-4e5a-c31f-36d79cf0aa8a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 17379.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_min, bikes_max = (min(bikes.min(numeric_only=True)),\n",
    "                        max(bikes.max(numeric_only=True)))\n",
    "bikes_min, bikes_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WfLvoqR_OF9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyKKjxJoNQuB"
   },
   "source": [
    "### Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hxPA3sXNQuB"
   },
   "source": [
    "Pandas makes computing quantiles easy. This is how to get the median of a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "n1GLqWOoNQuB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4848"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['atemp'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBWCtrCrNQuD"
   },
   "source": [
    "Of course, the `quantiles` method can take a tuple as its argument. Compute the 10th, 25th, 50th, 75th, and 90th percentiles in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "DfgKgsukPLUC",
    "outputId": "dc6f4470-c101-492f-9e37-81b0eaabc4d7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10    0.2424\n",
       "0.25    0.3333\n",
       "0.50    0.4848\n",
       "0.75    0.6212\n",
       "0.90    0.6970\n",
       "Name: atemp, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['atemp'].quantile((0.1, 0.25, 0.5, 0.75, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJnCB_bqNQuF"
   },
   "source": [
    "### Cuts\n",
    "\n",
    "Sometimes we want to split the sample not by the quantiles of the distribution but by the range of the data. Let's take a closer look at `atemp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "vn_cvvY-NQuF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bikes['atemp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ae7zUQp-NQuH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>6262</td>\n",
       "      <td>2011-09-23</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17021</th>\n",
       "      <td>17022</td>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.3939</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8634</th>\n",
       "      <td>8635</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.4925</td>\n",
       "      <td>108</td>\n",
       "      <td>205</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4014</th>\n",
       "      <td>4015</td>\n",
       "      <td>2011-06-21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>2365</td>\n",
       "      <td>2011-04-13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
       "6261      6262  2011-09-23       4   0     9  11        0        5   \n",
       "17021    17022  2012-12-17       4   1    12   0        0        1   \n",
       "8634      8635  2011-12-31       1   0    12  13        0        6   \n",
       "4014      4015  2011-06-21       3   0     6   4        0        2   \n",
       "2364      2365  2011-04-13       2   0     4  10        0        3   \n",
       "\n",
       "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
       "6261            1           3  0.62  0.5152  1.00     0.1045       1   \n",
       "17021           1           2  0.38  0.3939  0.87     0.0000       2   \n",
       "8634            0           1  0.50  0.4848  0.42     0.4925     108   \n",
       "4014            1           2  0.60  0.5455  0.88     0.1045       2   \n",
       "2364            1           2  0.40  0.4091  0.87     0.1940       4   \n",
       "\n",
       "       registered  cnt  \n",
       "6261           20   21  \n",
       "17021          26   28  \n",
       "8634          205  313  \n",
       "4014            7    9  \n",
       "2364           42   46  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thwFHrthNQuJ"
   },
   "source": [
    "Suppose we decide to sort these values into 4 bins of equal width, but we want to apply the resulting groups to the entire DataFrame. Basically, we need to add a row label that indicates which bin each sample belongs in. Let's call this label \"atemp_level\", and use the `cut` method to populate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "z7mXBeXMNQuJ"
   },
   "outputs": [],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vf3Q5vbQNQuL"
   },
   "source": [
    "What is `atemp_level`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhlx1W-VNQuL"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "QkPpsPwKPLUJ",
    "outputId": "1b03fe43-92f6-4dd5-f4a6-82269d4478ab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(type(atemp_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuDXdgfxNQuN"
   },
   "source": [
    "Here is a random sample of `atemp_level`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "4Qure0UbNQuN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15646    (0.5, 0.75]\n",
       "8620     (0.25, 0.5]\n",
       "6751     (0.5, 0.75]\n",
       "3215     (0.25, 0.5]\n",
       "416      (0.25, 0.5]\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, interval[float64, right]): [(-0.001, 0.25] < (0.25, 0.5] < (0.5, 0.75] < (0.75, 1.0]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q59qWmqfNQuO"
   },
   "source": [
    "So, by default, `cut` produces labels that indicate the bin boundaries for each element in the series it was applied to. Usually, we will specify labels that are appropriate to the discretisation we are applying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "VYsD8ZwDNQuP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5245     warm\n",
       "2646     mild\n",
       "14598    warm\n",
       "15846    warm\n",
       "15232    warm\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, object): ['cool' < 'mild' < 'warm' < 'hot']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4, labels = [\"cool\", \"mild\", \"warm\", \"hot\"])\n",
    "atemp_level.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WD-3g9qLNQuQ"
   },
   "source": [
    "Incorporate the new `atemp_level` column into the `bikes` DataFrame and use it to count the number of \"mild\" `atemp` entries in `season` 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "DyanX8vHPLUN",
    "outputId": "98656fd5-ccbb-4f72-84f6-bdf922a08c41",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['atemp_level'] = atemp_level\n",
    "bikes[(bikes.atemp_level == 'mild') & (bikes.season == 2)].season.count()  # Nb. could have used any column before count() in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZN-0yDQNQuR"
   },
   "source": [
    "*Nb. The `atemp_level` variable we created is what the R language calls a \"factor\". Pandas has introduced a new data type called \"category\" that is similar to R's factors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxMDzgRWNQuS"
   },
   "source": [
    "# Synthetic Data\n",
    "\n",
    "Sometimes we may want to generate test data, or we may need to initialise a series, matrix, or data frame for input to an algorithm. Numpy has several methods we can use for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W10uoBlNQuS"
   },
   "source": [
    "Execute the following, then check the shape and content of each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "bFR29OriNQuS"
   },
   "outputs": [],
   "source": [
    "# Creating arrays with initial values\n",
    "a = np.zeros((3))\n",
    "b = np.ones((1,3))\n",
    "c = np.random.randint(1,10,(2,3,4))   # randint(low, high, size)\n",
    "d = np.arange(4)\n",
    "e = np.array( [[1,2,3,4], [5,6,7,8]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JykYEjUHVppc"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "Load rock.csv and clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "013qY06xWuo-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load CSV File\n",
    "rock_csv = '../../DATA/rock.csv'\n",
    "rock = pd.read_csv(rock_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZQ4WoVYVppf"
   },
   "source": [
    "## Check Column Names\n",
    "\n",
    "Check column names and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "A7my2gZLWupC",
    "outputId": "9eb14657-1602-4dba-8246-6412cfe8549b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Song Clean', 'ARTIST CLEAN', 'Release Year', 'COMBINED', 'First?',\n",
       "       'Year?', 'PlayCount', 'F*G'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check column names\n",
    "rock.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KToV3ub3Vppg"
   },
   "source": [
    "## Replace Null Values With 0\n",
    "\n",
    "Check 'release_year' column whether this column has any null values or not. Replace null values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "ylXlQKPKWupX",
    "outputId": "e7e9f5f5-24fa-4588-a22b-aef439cdf58d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song Clean        0\n",
       "ARTIST CLEAN      0\n",
       "Release Year    577\n",
       "COMBINED          0\n",
       "First?            0\n",
       "Year?             0\n",
       "PlayCount         0\n",
       "F*G               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check are there any null values in any column\n",
    "rock.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ2GyN7MVpph"
   },
   "source": [
    "## Check Datatypes of Dataset\n",
    "\n",
    "Check datatypes of the dataset. Is there any column which should be int instead of object? Fix the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "hJe7YtjpPeXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2230 entries, 0 to 2229\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Song Clean    2230 non-null   object\n",
      " 1   ARTIST CLEAN  2230 non-null   object\n",
      " 2   Release Year  1653 non-null   object\n",
      " 3   COMBINED      2230 non-null   object\n",
      " 4   First?        2230 non-null   int64 \n",
      " 5   Year?         2230 non-null   int64 \n",
      " 6   PlayCount     2230 non-null   int64 \n",
      " 7   F*G           2230 non-null   int64 \n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 139.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "rock.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "ZiYZzf_dWupn",
    "outputId": "897ee7fd-e155-4c98-fd1a-8dccafe9c268",
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'release_year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'release_year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check values of release_year\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m rock[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_year\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'release_year'"
     ]
    }
   ],
   "source": [
    "# Check values of release_year\n",
    "rock['release_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCzoReoXVpph"
   },
   "source": [
    "## Check Min, Max of Each Column\n",
    "\n",
    "Is there any illogical value in any column? How can we fix that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "gtJfDfm5Wup0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_min_max(df):\n",
    "    # Check min, max of each column\n",
    "    print(df.describe().T[['min', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "eegPP172Wup3",
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'release_year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'release_year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a mask to find all rows with 0\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m song_facts_mask \u001b[38;5;241m=\u001b[39m rock[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_year\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m rock\u001b[38;5;241m.\u001b[39mloc[song_facts_mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_year\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mNaN\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'release_year'"
     ]
    }
   ],
   "source": [
    "# Create a mask to find all rows with 0\n",
    "song_facts_mask = rock['release_year'] == 0\n",
    "rock.loc[song_facts_mask, 'release_year'] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzJieuuyVppi"
   },
   "source": [
    "## Write Some Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jYAjnOVVppi"
   },
   "source": [
    "### Write a function that will take a row of a DataFrame and print out the song, artist, and whether or not the release date is < 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "10b7mMVRWupy",
    "outputId": "c42c3e82-1436-494e-f1c0-bb4a3482bf87",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song Clean      object\n",
       "ARTIST CLEAN    object\n",
       "Release Year    object\n",
       "COMBINED        object\n",
       "First?           int64\n",
       "Year?            int64\n",
       "PlayCount        int64\n",
       "F*G              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "rock.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "WtUu6LZXWup_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_song(row):\n",
    "    print('Song: ', row['song_clean'])\n",
    "    print('Artist: ', row['artist_clean'])\n",
    "    print('Released before 1970: ', row['release_year'] < 1970)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "lzYLXjLyWuqC",
    "outputId": "c227c1c9-3a01-457c-a602-b17c92070a6c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song Clean                     Caught Up in You\n",
       "ARTIST CLEAN                        .38 Special\n",
       "Release Year                               1982\n",
       "COMBINED        Caught Up in You by .38 Special\n",
       "First?                                        1\n",
       "Year?                                         1\n",
       "PlayCount                                    82\n",
       "F*G                                          82\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "7muJKOxgWuqH",
    "outputId": "b385fcfe-a657-40ea-9379-1efe2dcc1767",
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'song_clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'song_clean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check any row using index\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m check_song(rock\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[83], line 2\u001b[0m, in \u001b[0;36mcheck_song\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_song\u001b[39m(row):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSong: \u001b[39m\u001b[38;5;124m'\u001b[39m, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msong_clean\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArtist: \u001b[39m\u001b[38;5;124m'\u001b[39m, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_clean\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReleased before 1970: \u001b[39m\u001b[38;5;124m'\u001b[39m, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_year\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1970\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'song_clean'"
     ]
    }
   ],
   "source": [
    "# Check any row using index\n",
    "check_song(rock.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tk1XfgtkVppj"
   },
   "source": [
    "### Write a function that converts a column in a DataFrame to a numeric type and otherwise replaces entries with np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "bP__R2tDWuqS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_numeric(column):\n",
    "    column = pd.to_numeric(column, errors='coerce')\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'combined'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'combined'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rock[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'combined'"
     ]
    }
   ],
   "source": [
    "rock['combined']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEIsPER2Vppj"
   },
   "source": [
    "### Apply this last function to your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "PUgc9fTqWuqU",
    "outputId": "ffa2cb84-9cf5-4f30-c587-255d23951ca2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_year</th>\n",
       "      <th>first</th>\n",
       "      <th>year</th>\n",
       "      <th>playcount</th>\n",
       "      <th>fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1982.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>1981.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>1975.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>1983.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>1973.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2230 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      release_year  first  year  playcount   fg\n",
       "0           1982.0      1     1         82   82\n",
       "1              NaN      1     0          3    0\n",
       "2           1981.0      1     1         85   85\n",
       "3           1980.0      1     1         18   18\n",
       "4           1975.0      1     1          1    1\n",
       "...            ...    ...   ...        ...  ...\n",
       "2225           NaN      1     0          1    0\n",
       "2226        1981.0      1     1         32   32\n",
       "2227        1975.0      1     1        109  109\n",
       "2228        1983.0      1     1          1    1\n",
       "2229        1973.0      1     1          2    2\n",
       "\n",
       "[2230 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock[['release_year', 'first', 'year', 'playcount', 'fg']].apply(convert_to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jz86dxCFVppk"
   },
   "source": [
    "### 'Describe' the new DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2asO3_lDFm8"
   },
   "source": [
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "KiBKFpE-WuqW",
    "outputId": "4c84b43c-b7ba-4759-8555-83150ae5e81b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First?</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year?</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>0.741256</td>\n",
       "      <td>0.438043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PlayCount</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>16.872646</td>\n",
       "      <td>25.302972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F*G</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>15.048430</td>\n",
       "      <td>25.288366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count       mean        std  min  25%  50%   75%    max\n",
       "First?     2230.0   1.000000   0.000000  1.0  1.0  1.0   1.0    1.0\n",
       "Year?      2230.0   0.741256   0.438043  0.0  0.0  1.0   1.0    1.0\n",
       "PlayCount  2230.0  16.872646  25.302972  0.0  1.0  4.0  21.0  142.0\n",
       "F*G        2230.0  15.048430  25.288366  0.0  0.0  3.0  18.0  142.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe Dataframe\n",
    "rock.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlasiTKgDGdA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > >  2023 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
